<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="HDFS 分布式部署场景下最常见的为两种架构，一种是基本的分布式架构，另一种是 HA 架构。在生产环境中一般都会部署 HA 架构。">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="Ch02-Hadoop 之 HDFS 架构" />
<meta property="og:description" content="HDFS 分布式部署场景下最常见的为两种架构，一种是基本的分布式架构，另一种是 HA 架构。在生产环境中一般都会部署 HA 架构。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://acronymor.com/posts/apache-hadoop/ch02/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-03-17T00:00:00+08:00" />
<meta property="article:modified_time" content="2018-03-17T00:00:00+08:00" />
<title>Ch02-Hadoop 之 HDFS 架构 | acronymor&#39;s blog</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.c58292d36b18b675680ab9baea2029204537b839ea72f258746ec0f32ce8d6c8.css" integrity="sha256-xYKS02sYtnVoCrm66iApIEU3uDnqcvJYdG7A8yzo1sg=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.f5beb686abbc8c5af924219402ebff9fdf0db78c8f89d1fa45c60f3f5aebe91f.js" integrity="sha256-9b62hqu8jFr5JCGUAuv/n98Nt4yPidH6RcYPP1rr6R8=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?b8574e530940d019bc6fe14b11b86ab9";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>acronymor&#39;s blog</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  












  
<ul>
  
  <li>
    <a href="/posts/"  >
        Blog
      </a>
  </li>
  
  <li>
    <a href="/about/"  >
        About Me
      </a>
  </li>
  
  <li>
    <a href="https://github.com/acronymor"  target="_blank" rel="noopener">
        Github
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Ch02-Hadoop 之 HDFS 架构</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#1-hdfs-基础架构">1. HDFS 基础架构</a>
      <ul>
        <li><a href="#11-基本组成">1.1 基本组成</a></li>
        <li><a href="#12-checkpoint-过程">1.2 CheckPoint 过程</a>
          <ul>
            <li><a href="#第一阶段namenode-启动">第一阶段：NameNode 启动</a></li>
            <li><a href="#第二阶段secondary-namenode-工作">第二阶段：Secondary NameNode 工作</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#2-hdfs-ha-架构">2. HDFS HA 架构</a>
      <ul>
        <li><a href="#21-基本组成">2.1 基本组成</a></li>
        <li><a href="#22-checkpoint-过程">2.2 Checkpoint 过程</a></li>
      </ul>
    </li>
    <li><a href="#3-fsmage-和-edit-小细节">3. Fsmage 和 edit 小细节</a>
      <ul>
        <li><a href="#31-txnid">3.1 txnid</a></li>
        <li><a href="#32-fencing-隔离机制">3.2 Fencing 隔离机制</a></li>
      </ul>
    </li>
    <li><a href="#4-参考文献">4. 参考文献</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
<article class="markdown">
  <h1>
    <a href="/posts/apache-hadoop/ch02/">Ch02-Hadoop 之 HDFS 架构</a>
  </h1>
  
  <h5>March 17, 2018</h5>



  
  <div>
    
      <a href="/categories/Apache-Hadoop/">Apache Hadoop</a>
  </div>
  

  
  <div>
    
      <a href="/tags/hadoop/">hadoop</a>
  </div>
  



<p>HDFS 分布式部署场景下最常见的为两种架构，一种是基本的分布式架构，另一种是 HA 架构。在生产环境中一般都会部署 HA 架构。</p>
<h1 id="1-hdfs-基础架构">
  1. HDFS 基础架构
  <a class="anchor" href="#1-hdfs-%e5%9f%ba%e7%a1%80%e6%9e%b6%e6%9e%84">#</a>
</h1>
<h2 id="11-基本组成">
  1.1 基本组成
  <a class="anchor" href="#11-%e5%9f%ba%e6%9c%ac%e7%bb%84%e6%88%90">#</a>
</h2>
<p>HDFS 由 NameNode，Secondary NameNode，DataNode，Client 这四部分组成。NameNode 负责管理元数据和文件信息；Secondary NameNode 主要用于定期合并 Fsimage 文件和 Edits 文件；DataNode 用户完成数据的存储和读取等；Client 提供了各种操作 HDFS 的 API 接口。</p>
<blockquote>
<p>Fsimage 文件：也称为 Checkpoint 文件，记录了 HDFS 文件系统所有目录以及文件相关信息（Block 数量，副本数量，权限等信息），它是 NameNode 内存中元数据序列化后形成的文件。</p>
<p>Edits 文件：记录 Client 对指定 HDFS 文件的增删改操作</p>
</blockquote>
<p><img src="hdfs-nn.png" alt="hdfs-namenode" /></p>
<h2 id="12-checkpoint-过程">
  1.2 CheckPoint 过程
  <a class="anchor" href="#12-checkpoint-%e8%bf%87%e7%a8%8b">#</a>
</h2>
<p><img src="hdfs-ckpt.jpg" alt="hdfs-checkpoint" /></p>
<h3 id="第一阶段namenode-启动">
  第一阶段：NameNode 启动
  <a class="anchor" href="#%e7%ac%ac%e4%b8%80%e9%98%b6%e6%ae%b5namenode-%e5%90%af%e5%8a%a8">#</a>
</h3>
<ol>
<li>第一次启动 NameNode 格式化后，创建 Fsimage 和 Edits 文件。如果不是第一次启动，直接加载 Fsimage 和 Edits 文件到内存。</li>
<li>客户端对元数据进行增删改的请求。</li>
<li>NameNode 记录操作日志，更新滚动日志。</li>
<li>NameNode 在内存中对数据进行增删改。</li>
</ol>
<h3 id="第二阶段secondary-namenode-工作">
  第二阶段：Secondary NameNode 工作
  <a class="anchor" href="#%e7%ac%ac%e4%ba%8c%e9%98%b6%e6%ae%b5secondary-namenode-%e5%b7%a5%e4%bd%9c">#</a>
</h3>
<ol>
<li>Secondary NameNode 询问 NameNode 是否需要 CheckPoint。直接带回 NameNode 是否执行检查点操作结果。</li>
<li>Secondary NameNode 请求执行 CheckPoint。</li>
<li>NameNode 滚动正在写的 Edits 日志。</li>
<li>将滚动前的编辑日志和镜像文件拷贝到 Secondary NameNode。</li>
<li>Secondary NameNode 加载编辑日志和镜像文件到内存并合并。</li>
<li>生成新的镜像文件 fsimage.ckpt。</li>
<li>拷贝 fsimage.ckpt 到 NameNode。</li>
<li>NameNode 将 fsimage.ckpt 重新命名成 fsimage。</li>
</ol>
<h1 id="2-hdfs-ha-架构">
  2. HDFS HA 架构
  <a class="anchor" href="#2-hdfs-ha-%e6%9e%b6%e6%9e%84">#</a>
</h1>
<h2 id="21-基本组成">
  2.1 基本组成
  <a class="anchor" href="#21-%e5%9f%ba%e6%9c%ac%e7%bb%84%e6%88%90">#</a>
</h2>
<p>HDFS 中，DataNode 自身保存了多个副本，所以某种意义上来说本身就是 HA 架构；NameNode 和 Secondary NameNode 本身却只是单点结构，如果 NameNode 宕机，那么 HDFS 将无法对外提供服务，所以社区就设计了 HA 架构（也叫做 QJM(Quorum Journal Manager) ）。其结构如下图所示。</p>
<p><img src="hdfs-ha.png" alt="hdfs-ha" /></p>
<p>原理较为简单，将 NameNode 变成多个并将其划分不同角色（1 个 Active NameNode，n 个 Standy NameNode），只让 Active NameNode 提供 NameNode 的服务。接着设计了个名称为 ZKFC 的监控组件，不断的监控所有 NameNode 状态，如果发现 Active NameNode 宕机了，便从 Standby NameNode 中选一个并切换角色为  Active NameNode，同时也会保证只有一个 Active NameNode 在线。</p>
<p>为了能够保证所有 NameNode 看到的 edit 文件一致，所以社区又设计了 JournalNode Cluster（基于 Poxos 算法保证 edit 一致性），这样只需要向 JournalNode Cluster 中写 edit 文件便可。</p>
<h2 id="22-checkpoint-过程">
  2.2 Checkpoint 过程
  <a class="anchor" href="#22-checkpoint-%e8%bf%87%e7%a8%8b">#</a>
</h2>
<p><img src="qjm-arch.png" alt="qjm-arch" /></p>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>FSEditLog</td>
<td>所有 EditLog 操作的入口</td>
</tr>
<tr>
<td>JournalSet</td>
<td>集成本地磁盘和 JournalNode 集群上 EditLog 的相关操作</td>
</tr>
<tr>
<td>FileJournalManager</td>
<td>实现本地磁盘上 EditLog 操作</td>
</tr>
<tr>
<td>QuorumJournalManager</td>
<td>实现 JournalNode 集群 EditLog 操作</td>
</tr>
<tr>
<td>AsyncLoggerSet</td>
<td>实现 JournalNode 集群 EditLog 的写操作集合</td>
</tr>
<tr>
<td>AsyncLogger</td>
<td>发起 RPC 请求到 JournalNode，执行具体的日志同步功能</td>
</tr>
<tr>
<td>JournalNodeHttpServer</td>
<td>运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求</td>
</tr>
<tr>
<td>JournalNodeRpcServer</td>
<td>运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求</td>
</tr>
</tbody>
</table>
<blockquote>
<p>基础架构中的 NameNode 功能由 HA 架构中的 Active NameNode 完成，那 Secondary NameNode 岂不是没了？那 fsimage 和 edit 的工作谁来做呢？</p>
<p>事实上  Secondary NameNode  的确没了，其 merge 工作则由 Standby NameNode 取而代之。它维护了一个线程，会不断的监听 JournalNode Cluster 中的 edit 文件变更，如果满足条件（比如时间到了）那么便拉取 edit 文件并与 fsimage 文件合并，最后重新发送回 Active NameNode。</p>
</blockquote>
<h1 id="3-fsmage-和-edit-小细节">
  3. Fsmage 和 edit 小细节
  <a class="anchor" href="#3-fsmage-%e5%92%8c-edit-%e5%b0%8f%e7%bb%86%e8%8a%82">#</a>
</h1>
<h2 id="31-txnid">
  3.1 txnid
  <a class="anchor" href="#31-txnid">#</a>
</h2>
<p>文件名自带 txnid，可以用来确认 fsimage 和 edits 之间的关系。同目录中还有一个名为 seen_txid 的文件，保存了最后一个 edits 文件名的 txnid。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>edits 文件名称：edits_0000000000000000264-edits_0000000000000000267
</span></span><span style="display:flex;"><span>fsimage 文件名称：fsimage_0000000000000000267
</span></span></code></pre></div><p>比如上述两个文件，fsimage (*-0267) 已经将 edits 文件  (*0264-*267) 合并进来了，此时可以删除 edits 文件  (*0264-*267)  文件。</p>
<h2 id="32-fencing-隔离机制">
  3.2 Fencing 隔离机制
  <a class="anchor" href="#32-fencing-%e9%9a%94%e7%a6%bb%e6%9c%ba%e5%88%b6">#</a>
</h2>
<p>HDFS HA 中 利用了 Fencing 机制来避免脑裂问题，将先前的 Active 节点 杀死，然后将本地 NameNode 转换为 Active 状态。Hadoop 公共库中对外提供了两种 fenching 实现：</p>
<ul>
<li>sshfence：通过 ssh 登陆目标节点上，使用命令 fuser 将进程杀死（通过 tcp 端口号定位进程 pid，该方法比 jps 命令更准确）</li>
<li>shellfence（缺省实现），执行一个用户事先定义的 shell 命令（脚本）完成隔离</li>
</ul>
<h1 id="4-参考文献">
  4. 参考文献
  <a class="anchor" href="#4-%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae">#</a>
</h1>
<ul>
<li><a href="https://www.cnblogs.com/yuexiuping/p/14806782.html">Hadoop 之 HDFS</a></li>
<li><a href="https://blog.csdn.net/weixin_52851967/article/details/127070265">Namenode 与 SecondaryNameNode</a></li>
<li><a href="https://xie.infoq.cn/article/c62c656fcc819f3d5ad1536fe">详解 HDFS 底层交互原理</a></li>
<li><a href="https://blog.csdn.net/breakout_alex/article/details/88171114">HADOOP-QJM 原理</a></li>
<li><a href="https://www.malaoshi.top/show_1IX26KeAQn5B.html">hadoop3.x ha 高可用-QJM 解决方案、ZKFailoverController、Fencing 隔离机制、Journal Node 同步数据</a></li>
</ul></article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#1-hdfs-基础架构">1. HDFS 基础架构</a>
      <ul>
        <li><a href="#11-基本组成">1.1 基本组成</a></li>
        <li><a href="#12-checkpoint-过程">1.2 CheckPoint 过程</a>
          <ul>
            <li><a href="#第一阶段namenode-启动">第一阶段：NameNode 启动</a></li>
            <li><a href="#第二阶段secondary-namenode-工作">第二阶段：Secondary NameNode 工作</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#2-hdfs-ha-架构">2. HDFS HA 架构</a>
      <ul>
        <li><a href="#21-基本组成">2.1 基本组成</a></li>
        <li><a href="#22-checkpoint-过程">2.2 Checkpoint 过程</a></li>
      </ul>
    </li>
    <li><a href="#3-fsmage-和-edit-小细节">3. Fsmage 和 edit 小细节</a>
      <ul>
        <li><a href="#31-txnid">3.1 txnid</a></li>
        <li><a href="#32-fencing-隔离机制">3.2 Fencing 隔离机制</a></li>
      </ul>
    </li>
    <li><a href="#4-参考文献">4. 参考文献</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












