<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="HDFS 读写过程需要 NameNode，DataNode，Client 等组件共同参与才能完成，所以 HDFS 的读写流程还是比较复杂的。">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="Ch03-Hadoop 之 HDFS 读写流程" />
<meta property="og:description" content="HDFS 读写过程需要 NameNode，DataNode，Client 等组件共同参与才能完成，所以 HDFS 的读写流程还是比较复杂的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://acronymor.com/posts/apache-hadoop/ch03/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-03-19T00:00:00+08:00" />
<meta property="article:modified_time" content="2018-03-19T00:00:00+08:00" />

<title>Ch03-Hadoop 之 HDFS 读写流程 | acronymor&#39;s blog</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.c58292d36b18b675680ab9baea2029204537b839ea72f258746ec0f32ce8d6c8.css" integrity="sha256-xYKS02sYtnVoCrm66iApIEU3uDnqcvJYdG7A8yzo1sg=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.cefc60a5a923c581f23ff6c4d8ad19eb90dc2beb11085ab7b4078ce23b741e3a.js" integrity="sha256-zvxgpakjxYHyP/bE2K0Z65DcK&#43;sRCFq3tAeM4jt0Hjo=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?b8574e530940d019bc6fe14b11b86ab9";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>acronymor&#39;s blog</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  












  
<ul>
  
  <li>
    <a href="/posts/"  >
        Blog
      </a>
  </li>
  
  <li>
    <a href="/about/"  >
        About Me
      </a>
  </li>
  
  <li>
    <a href="https://github.com/acronymor"  target="_blank" rel="noopener">
        Github
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Ch03-Hadoop 之 HDFS 读写流程</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#1-基本概念">1. 基本概念</a></li>
    <li><a href="#2-写入流程">2. 写入流程</a></li>
    <li><a href="#3-读取流程">3. 读取流程</a></li>
    <li><a href="#4-参考文献">4. 参考文献</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
<article class="markdown">
  <h1>
    <a href="/posts/apache-hadoop/ch03/">Ch03-Hadoop 之 HDFS 读写流程</a>
  </h1>
  
  <h5>March 19, 2018</h5>



  
  <div>
    
      <a href="/categories/Apache-Hadoop/">Apache Hadoop</a>
  </div>
  

  
  <div>
    
      <a href="/tags/hadoop/">Hadoop</a>
  </div>
  



<p>HDFS 读写过程需要 NameNode，DataNode，Client 等组件共同参与才能完成，所以 HDFS 的读写流程还是比较复杂的。</p>
<h1 id="1-基本概念">
  1. 基本概念
  <a class="anchor" href="#1-%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5">#</a>
</h1>
<p>在 HDFS 中，文件存储是按照数据块（Block）为单位进行存储的，在读写数据时，DFSOutputStream 使用 Packet 类来封装一个数据包。每个 Packet 包含了若干个 chunk 和对应的 checksum。</p>
<ul>
<li>Block: HDFS 上的文件都是分块存储的，即把一个文件物理划分为一个 Block 块存储。Hadoop 2.X/3.X 默认块大小为 128 M，1.X 为 64M。</li>
<li>Packet: 是 Client 端向 DataNode  或 DataNode 的 Pipline 之间传输数据的基本单位，默认 64 KB</li>
<li>Chunk: Chunk 是最小的单位，它是 Client 向 DataNode 或 DataNode PipLine 之间进行数据校验的基本单位，默认 512 Byte，因为用作校验，所以每个 Chunk 需要带有 4 Byte 的校验位，实际上每个 Chunk 写入 Packtet 的大小为 516 Byte。</li>
</ul>
<h1 id="2-写入流程">
  2. 写入流程
  <a class="anchor" href="#2-%e5%86%99%e5%85%a5%e6%b5%81%e7%a8%8b">#</a>
</h1>
<p><img src="hdfs-write.png" alt="hdfs-write" /></p>
<ul>
<li>客户端通过分布式文件系统 DistributeFileSystem 向 NameNode 发送上传文件请求，NameNode 收到请求后检查目标文件是否存，父目录是否存在，之后响应客户端可以上传文件。</li>
<li>客户端收到响应后向 NameNode 请求上传第一个块信息，并请求返回 DataNode，NameNode 收到请求后根据文件的备份数量返回相应数量的 DataNode 节点。
客户端收到来自 NameNode 返回的节点信息，通过 FSDataOutPutStream 向离客户端最近的节点上传数据，第一个节点收到请求后会继续调用下一个的 DataNode 节点，然后下一个节点去调用自己的下一个节点，直到最后一个节点，将通信管道 PipeLine 建立，然后各个节点从后向前逐级应答客户端。</li>
<li>通信管道 PipeLine 建立完成后，客户端先将磁盘中的块信息读到内存，然后通过 FSDataOutPutStream 开始以 Packet 为单位传送块数据，其中 Packet 为 64K 由 Chunk 组成，每个 Chunk 为 512B，并且每个 Chunk 还包含了 4B 的 crc 校验信息，共 516B。当 Packet 被 Chunk 填满以后就将 Packet 放入到应答队列 DataQueue 队列中等待，再从该队列中将 Packet 取出存入另一个队列 ACKQueue 队列中，然后将该 Patcket 发送给离客户端最近的 DataNode。</li>
<li>第一个 DataNode 收到数据后，会将该数据传递给下一个 DataNode，每个节点收到数据后都会逐级传递给下个节点直至 PipeLine 中的最后一个节点。并且在传输 Packet 的过程中，每向 DataNode 发送一个 Packet 数据客户端都会等待来自 DataNode 的应答响应，若响应则代表当前节点收来自客户端发送的数据，若没有响应时会将 ACKQueun 中的 Packet 数据重新放回到 DataQueue 队列中等待再次发送，避免了数据丢失。</li>
<li>当第一个 Block 块信息传输完成后，客户端会再次请求 NameNode 上传第其他个 Block 块信息。</li>
</ul>
<h1 id="3-读取流程">
  3. 读取流程
  <a class="anchor" href="#3-%e8%af%bb%e5%8f%96%e6%b5%81%e7%a8%8b">#</a>
</h1>
<p><img src="hdfs-read.png" alt="hdfs-read" /></p>
<ul>
<li>客户端通过 DistributeFileSystem 向 NameNode 申请下载文件请求，NameNode 收到客户端下载请求后通过
查询文件的元数据找到文件所在的 DataNode，然后返回包含所有该下载文件的 DataNode 给客户端。</li>
<li>客户端收到 NameNode 发送回来的 DataNode 信息后，会寻找距当前节点最近的 DataNode 节点请求下载文件。</li>
<li>DataNode 收到客户端下载请求后开始向客户端发送数据，先将磁盘中的块信息通过输入流读出到内存，然后以 Packet 作为单位校验，传输给客户端。</li>
<li>客户端收到 Packet 后先将文件读入到内存然后通过输出流写出到磁盘存储。</li>
</ul>
<h1 id="4-参考文献">
  4. 参考文献
  <a class="anchor" href="#4-%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae">#</a>
</h1>
<ul>
<li><a href="https://xie.infoq.cn/article/c62c656fcc819f3d5ad1536fe">详解 HDFS 底层交互原理</a></li>
<li><a href="https://www.cnblogs.com/yuexiuping/p/14806782.html">Hadoop 之 HDFS</a></li>
</ul></article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#1-基本概念">1. 基本概念</a></li>
    <li><a href="#2-写入流程">2. 写入流程</a></li>
    <li><a href="#3-读取流程">3. 读取流程</a></li>
    <li><a href="#4-参考文献">4. 参考文献</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












